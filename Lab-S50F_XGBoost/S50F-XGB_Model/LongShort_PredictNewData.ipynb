{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from datetime import datetime\n",
    "\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "\n",
    "import os\n",
    "import sys \n",
    "\n",
    "import pyodbc\n",
    "\n",
    "from datetime  import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Error  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WriteLogError(error):\n",
    "        f = open('ml_error.csv', 'a')\n",
    "        error_str=f'{datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")}|{repr(error)}\\n'\n",
    "        f.write(error_str)\n",
    "        f.close()\n",
    "        print(error_str) \n",
    "        raise error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the most critical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML-StrategyTrade=long\n"
     ]
    }
   ],
   "source": [
    "#x_date=datetime(2020,5,11,9,45,0)\n",
    "x_date=datetime.now()\n",
    "\n",
    "\n",
    "isRunByscheduling=False\n",
    "\n",
    "onlyLastRecord=False\n",
    "\n",
    "isSavedDB=False\n",
    "#CONSTANT VARIABLE\n",
    "predictionColName=\"Signal\"\n",
    "\n",
    "strategyName='long'\n",
    "\n",
    "\n",
    "if isRunByscheduling :\n",
    " n = len(sys.argv) \n",
    " print(\"Total arguments passed:\", n) \n",
    "\n",
    " try:\n",
    "\n",
    "  if n==2:\n",
    "    strategyName= sys.argv[1]\n",
    "  else  :\n",
    "    raise Exception(\"you must specify the strategyName parameter either of long or short\") \n",
    " except Exception as error:\n",
    "    WriteLogError(error) \n",
    "\n",
    "print(f\"ML-StrategyTrade={strategyName}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set all Path Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_path=os.path.abspath(r'E:\\PredictML-Script\\S50F15M_FeaturesExploration\\ChkHolidayForYear.csv')\n",
    "\n",
    "if onlyLastRecord:\n",
    "  #Live Run with last data\n",
    " abfeatures_file='S50M15_ListFeatures.csv'\n",
    " ml_file_path='E:\\\\PredictML-Script\\\\S50F15M_FeaturesExploration\\\\UnlabeledData\\\\'\n",
    "\n",
    "else:\n",
    "#Test Run with bulk data\n",
    " abfeatures_file='S50M15_ListFeatures_MultipleRows.csv'\n",
    " ml_file_path='E:\\\\PredictML-Script\\\\S50F15M_FeaturesExploration\\\\UnlabeledData\\\\'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Model File Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LONG_S50IF\n"
     ]
    }
   ],
   "source": [
    "if strategyName=='long':\n",
    " modelfile=os.path.abspath(r'E:\\PredictML-Script\\Models\\long_S50M15_XGB-160x8x01_01-2007t12-2018_b100520_1139.joblib.dat')\n",
    " trade_symbol='LONG_S50IF'\n",
    "else:\n",
    " modelfile=os.path.abspath(r'E:\\PredictML-Script\\Models\\short_S50M15_XGB-160x8x01_01-2007t12-2018_b100520_1138.joblib.dat')\n",
    " trade_symbol='SHORT_S50IF'\n",
    " \n",
    "print(trade_symbol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function For Check Market Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CheckValidPath(path):\n",
    "        if os.path.exists(path):\n",
    "            return True\n",
    "        else:\n",
    "            raise Exception(f'Invalid path: {path}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10:01 is before the first triger in the morning  at 10:02  for first bar at 10:00\n",
    "# 12:26 is after the last trigter in the morning at 12:17 for first bar at 12:15\n",
    "\n",
    "# 14:31 is before the first triger after noon  at 14:32  for first bar at 14:30\n",
    "# 16:56 is after the last trigter after noon at 16:47 for first bar at 16:45\n",
    "\n",
    "def CheckMarketTime(current_time):\n",
    "  # check time 10:00-17:00\n",
    "  isTradeTime_morning=current_time.strftime('%H:%M:%S')>=10:01:00' and current_time.strftime('%H:%M:%S')<='12:36:00' \n",
    "  isTradeTime_noon=current_time.strftime('%H:%M:%S')>='14:31:00' and current_time.strftime('%H:%M:%S')<='17:06:00' \n",
    "  \n",
    "  return  isTradeTime_morning or isTradeTime_noon\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CheckMarketDay(current_time):\n",
    "   w_no= int(current_time.strftime('%w'))\n",
    "   if w_no>=1 and w_no<=5 :\n",
    "      return True\n",
    "   else :\n",
    "      return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CheckNotHoliday(df_holiday,current_time):\n",
    "\n",
    " holiday_today=current_time.strftime('%Y%m%d')\n",
    "\n",
    " df_holiday[0]= current_time.strftime('%Y')+df_holiday[0]\n",
    " #print(df_holiday)\n",
    "\n",
    " if holiday_today not in df_holiday[0].tolist():\n",
    "  return True\n",
    " else:\n",
    "  return False\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Trading Time&Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time\n",
      "11/05/2020\n",
      "09:45:00\n",
      "===========check trade time&day===========\n",
      "IsMarkerTime =  True\n",
      "IsMarketDay =  True\n",
      "IsNotholiday =  True\n",
      "#######################################################\n",
      "Let go it is time to trade\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Current time\")\n",
    "print(x_date.strftime('%d/%m/%Y'))\n",
    "print(x_date.strftime('%H:%M:%S'))\n",
    "#print(x_today)\n",
    "\n",
    "print(\"===========check trade time&day===========\")\n",
    "\n",
    "IsMarketTime=CheckMarketTime(x_date)\n",
    "print('IsMarkerTime = ',CheckMarketTime(x_date))\n",
    "\n",
    "IsMarketDay=CheckMarketDay(x_date)\n",
    "print('IsMarketDay = ',CheckMarketDay(x_date))\n",
    "\n",
    "\n",
    "try:\n",
    " df_holiday =pd.read_csv(holiday_path,header =  None,dtype=object)\n",
    "\n",
    " IsNotHoliday=CheckNotHoliday(df_holiday ,x_date)\n",
    " print('IsNotholiday = ',IsNotHoliday)\n",
    "\n",
    "\n",
    " IsTradable=IsMarketTime and  IsMarketDay and  IsNotHoliday\n",
    " if not IsTradable:\n",
    "   sys.exit((\"It is not trading time\")) \n",
    "\n",
    "\n",
    " print(\"#######################################################\")\n",
    " print(\"Let go it is time to trade\")\n",
    "\n",
    "except Exception as error:\n",
    " WriteLogError(error) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check all Path Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model File=  E:\\PredictML-Script\\Models\\long_S50M15_XGB-160x8x01_01-2007t12-2018_b100520_1139.joblib.dat\n",
      "Feature Path=  E:\\PredictML-Script\\S50F15M_FeaturesExploration\\UnlabeledData\\\n",
      "New Data Feature File=  E:\\PredictML-Script\\S50F15M_FeaturesExploration\\UnlabeledData\\S50M15_ListFeatures_MultipleRows.csv\n",
      "Holiday Path=  E:\\PredictML-Script\\S50F15M_FeaturesExploration\\ChkHolidayForYear.csv\n"
     ]
    }
   ],
   "source": [
    "predicttime=datetime.now().strftime('-p%d%m%y_%H%M')\n",
    "prediction_file=f'{strategyName}{predictionColName}_{predicttime}_{abfeatures_file}'\n",
    "\n",
    "\n",
    "path_abfeatures= os.path.abspath(f'{ml_file_path}{abfeatures_file}')\n",
    "path_prediction=ml_file_path+prediction_file\n",
    "\n",
    "\n",
    "try:\n",
    "    if CheckValidPath(modelfile) and CheckValidPath(ml_file_path) and CheckValidPath(path_abfeatures) and CheckValidPath(holiday_path)  :\n",
    "       print(\"Model File= \",modelfile)\n",
    "       print(\"Feature Path= \",ml_file_path)\n",
    "       print(\"New Data Feature File= \",path_abfeatures)\n",
    "       print(\"Holiday Path= \",holiday_path)\n",
    "     \n",
    "except Exception as error:\n",
    "       WriteLogError(error)                                                                                \n",
    "                                                                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Load unseen data file to predict by model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-Load unseen data file from E:\\PredictML-Script\\S50F15M_FeaturesExploration\\UnlabeledData\\S50M15_ListFeatures_MultipleRows.csv  succeeded.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22 entries, 0 to 21\n",
      "Data columns (total 23 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Ticker                  22 non-null     object \n",
      " 1   Date/Time               22 non-null     object \n",
      " 2   open                    22 non-null     float64\n",
      " 3   high                    22 non-null     float64\n",
      " 4   low                     22 non-null     float64\n",
      " 5   close                   22 non-null     float64\n",
      " 6   indy_ma-550             22 non-null     float64\n",
      " 7   indy_ma-1100            22 non-null     float64\n",
      " 8   indy_hh-550             22 non-null     float64\n",
      " 9   indy_ll-550             22 non-null     float64\n",
      " 10  indy_mid-550            22 non-null     float64\n",
      " 11  indy_hh2-1100           22 non-null     float64\n",
      " 12  indy_ll2-1100           22 non-null     float64\n",
      " 13  indy_mid2-1100          22 non-null     float64\n",
      " 14  indy_macd110-440        22 non-null     float64\n",
      " 15  indy_signal110-440-110  22 non-null     float64\n",
      " 16  indy_hist_macd110-440   22 non-null     float64\n",
      " 17  indy_rsi25-ma20         22 non-null     float64\n",
      " 18  indy_6ATRTrail_DC-110   22 non-null     float64\n",
      " 19  cate_3trend-550_ma110   22 non-null     int64  \n",
      " 20  cate_2trend-1100_ma220  22 non-null     int64  \n",
      " 21  cate_rannkHL1100-ma66   22 non-null     int64  \n",
      " 22  cate_CombineTrend       22 non-null     int64  \n",
      "dtypes: float64(17), int64(4), object(2)\n",
      "memory usage: 4.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    dataset =pd.read_csv(path_abfeatures)\n",
    "    \n",
    "    #For one record\n",
    "    #if onlyLastRecord==True:\n",
    "     #dataset =dataset.tail(1)\n",
    "    \n",
    "    if dataset.shape[0]>0:\n",
    "        print(f'1-Load unseen data file from {path_abfeatures}  succeeded.')\n",
    "        dataset['Ticker']=trade_symbol\n",
    "    else:\n",
    "        raise Exception(f'No feature row  in dataframe from file,please check Amibroker Exploration')    \n",
    "    \n",
    "except Exception as error_x:\n",
    "        WriteLogError(f'{error_x} {path_abfeatures}')\n",
    "\n",
    "\n",
    "print(dataset.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Create dataframe succeeded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-Create dataframe succeeded.\n"
     ]
    }
   ],
   "source": [
    "noFeature_col=['Ticker','Date/Time' ,'open','high','low','close']\n",
    "dfx_ohlc=dataset[noFeature_col]\n",
    "dfx_feature=dataset.drop(columns=noFeature_col)\n",
    "print('2-Create dataframe succeeded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Ticker           Date/Time   open   high    low  close\n",
      "19  LONG_S50IF  11/5/2020 16:15:00  862.3  862.3  860.6  861.5\n",
      "20  LONG_S50IF  11/5/2020 16:30:00  861.4  861.7  860.1  860.4\n",
      "21  LONG_S50IF  11/5/2020 16:45:00  860.5  860.5  858.2  860.3\n"
     ]
    }
   ],
   "source": [
    "print(dfx_ohlc.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    indy_ma-550  indy_ma-1100  indy_hh-550  indy_ll-550  indy_mid-550  \\\n",
      "19       826.95        806.26        873.4        728.0         800.7   \n",
      "20       827.18        806.20        873.4        728.0         800.7   \n",
      "21       827.39        806.14        873.4        728.0         800.7   \n",
      "\n",
      "    indy_hh2-1100  indy_ll2-1100  indy_mid2-1100  indy_macd110-440  \\\n",
      "19          946.2          623.0           784.6             14.34   \n",
      "20          946.2          623.0           784.6             14.30   \n",
      "21          946.2          623.0           784.6             14.27   \n",
      "\n",
      "    indy_signal110-440-110  indy_hist_macd110-440  indy_rsi25-ma20  \\\n",
      "19                   20.44                  -6.10            63.80   \n",
      "20                   20.32                  -6.02            63.69   \n",
      "21                   20.20                  -5.93            63.60   \n",
      "\n",
      "    indy_6ATRTrail_DC-110  cate_3trend-550_ma110  cate_2trend-1100_ma220  \\\n",
      "19                 852.99                      3                       0   \n",
      "20                 853.09                      3                       0   \n",
      "21                 853.15                      3                       0   \n",
      "\n",
      "    cate_rannkHL1100-ma66  cate_CombineTrend  \n",
      "19                      4                  4  \n",
      "20                      4                  4  \n",
      "21                      4                  4  \n"
     ]
    }
   ],
   "source": [
    "print(dfx_feature.tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Create numpy array as input for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[822.87 807.26 873.4  728.   800.7  946.2  623.   784.6   15.41  22.88\n",
      "   -7.47  46.3  852.24   3.     0.     4.     3.  ]\n",
      " [823.07 807.2  873.4  728.   800.7  946.2  623.   784.6   15.28  22.75\n",
      "   -7.47  47.06 852.24   3.     0.     4.     3.  ]\n",
      " [823.28 807.14 873.4  728.   800.7  946.2  623.   784.6   15.16  22.62\n",
      "   -7.46  47.92 852.16   3.     0.     4.     3.  ]]\n",
      "3-Create numpy array succeeded.\n"
     ]
    }
   ],
   "source": [
    "X_new=dfx_feature.values\n",
    "print(X_new[:3,:])\n",
    "print('3-Create numpy array succeeded.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Load model file as strategy for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4-Loaded model from: E:\\PredictML-Script\\Models\\long_S50M15_XGB-160x8x01_01-2007t12-2018_b100520_1139.joblib.dat succeeded\n"
     ]
    }
   ],
   "source": [
    " try:  \n",
    "   loaded_model = joblib.load(modelfile)\n",
    "  \n",
    "   #loaded_model =  pickle.load(open(modelfile, \"rb\"))\n",
    "  \n",
    "   print(f\"4-Loaded model from: {modelfile} succeeded\")\n",
    " except Exception as error:\n",
    "   WriteLogError(f'cannot load file {modelfile} {error}')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Predict unseen feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-Predict new data succeeded.\n"
     ]
    }
   ],
   "source": [
    "yPredited = loaded_model.predict(X_new)\n",
    "predictions = [round(value) for value in yPredited]\n",
    "\n",
    "prediction_df=pd.DataFrame(data= {predictionColName: predictions })\n",
    "\n",
    "df_result=pd.concat([dfx_ohlc,prediction_df],axis=1)\n",
    "print('5-Predict new data succeeded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Predict result\n",
      "=======================================================================\n",
      "       Ticker           Date/Time   open   high    low  close  Signal\n",
      "0  LONG_S50IF   11/5/2020 9:45:00  852.0  854.5  851.5  854.2       0\n",
      "1  LONG_S50IF  11/5/2020 10:00:00  854.3  856.3  852.8  853.9       0\n",
      "2  LONG_S50IF  11/5/2020 10:15:00  854.0  858.8  853.8  858.0       0\n",
      "3  LONG_S50IF  11/5/2020 10:30:00  858.1  861.9  857.8  861.6       0\n",
      "4  LONG_S50IF  11/5/2020 10:45:00  861.5  862.2  859.0  860.8       0\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample Predict result\")\n",
    "print(\"=======================================================================\")\n",
    "print(df_result[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1 Save To CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isSavedDB==False:\n",
    " df_result.drop(columns=['Ticker'],inplace=True)\n",
    " df_result.to_csv(path_prediction,index=False)\n",
    " print('6-Save predction result to csv succeeded.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2 Save To DB (check database server and database name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'WriteLogError' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f403857f04a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m  \u001b[1;32mif\u001b[0m \u001b[0misSavedDB\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m   conn = pyodbc.connect('Driver={SQL Server};'\n",
      "\u001b[1;31mNameError\u001b[0m: name 'isSavedDB' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f403857f04a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m  \u001b[1;31m#=================================================================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m   \u001b[0mWriteLogError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'WriteLogError' is not defined"
     ]
    }
   ],
   "source": [
    "try:\n",
    " if isSavedDB==True:\n",
    "  conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                       'Server=localhost\\SQLEXPRESS;'\n",
    "                       'Database=Tfex_AB_ML;'\n",
    "                       'Trusted_Connection=yes;')\n",
    "\n",
    "  cursor=conn.cursor()\n",
    "\n",
    "  for index,row in df_result.iterrows():\n",
    "      #print(datetime.strptime(row[\"Date/Time\"],'%d/%m/%Y %H:%M:%S'))\n",
    "      #print(row[\"Ticker\"],row[\"Date/Time\"])\n",
    "      sqlcmd=\"INSERT INTO S50F_ML ([SYMBOL],[xDATE],[xOPEN],[xHIGH],[xLOW],[xCLOSE],[xVolume],[Signal],[UpdateTime]) VALUES(?,?,?,?,?,?,?,?,?)\"\n",
    "      cursor.execute(sqlcmd,row[\"Ticker\"],datetime.strptime(row[\"Date/Time\"],'%d/%m/%Y %H:%M:%S'),row[\"open\"],row[\"high\"],row[\"low\"],row[\"close\"],0,row[predictionColName],datetime.now())\n",
    "      conn.commit()\n",
    "    \n",
    "  cursor.commit()\n",
    "  cursor.close()\n",
    "  conn.close()\n",
    "  print('6-Save predction result to database succeeded.')\n",
    " #=================================================================\n",
    "except Exception as error :\n",
    "  WriteLogError(error)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
