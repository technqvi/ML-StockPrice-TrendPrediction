{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CrossValidation-S50F-DNN & Optimize Tune Epcoch and BatchSize\n",
    "\n",
    "\n",
    "Baseline Neural Network Model Performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c2761756b3e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_random_seed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mset_random_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "xseed=38\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(xseed)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(xseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Binary Classification with Sonar Dataset: Baseline\n",
    "import numpy\n",
    "import pandas\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras import models\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import joblib\n",
    "\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "st='2007'\n",
    "ed='2020'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Dev-Trong\\DataSet\\ML-Long_S50M15_07ToNow-Train.csv\n"
     ]
    }
   ],
   "source": [
    "filename='ML-Long_S50M15_07ToNow-Train.csv'\n",
    "filepath=os.path.abspath(f'D:\\Dev-Trong\\DataSet\\/{filename}')\n",
    "print(filepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data by WFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70693, 22)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 70693 entries, 2007-01-03 09:45:00 to 2020-06-10 16:45:00\n",
      "Data columns (total 22 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   open                    70693 non-null  float64\n",
      " 1   high                    70693 non-null  float64\n",
      " 2   low                     70693 non-null  float64\n",
      " 3   close                   70693 non-null  float64\n",
      " 4   indy_ma-550             70693 non-null  float64\n",
      " 5   indy_ma-1100            70693 non-null  float64\n",
      " 6   indy_hh-550             70693 non-null  float64\n",
      " 7   indy_ll-550             70693 non-null  float64\n",
      " 8   indy_mid-550            70693 non-null  float64\n",
      " 9   indy_hh2-1100           70693 non-null  float64\n",
      " 10  indy_ll2-1100           70693 non-null  float64\n",
      " 11  indy_mid2-1100          70693 non-null  float64\n",
      " 12  indy_macd110-440        70693 non-null  float64\n",
      " 13  indy_signal110-440-110  70693 non-null  float64\n",
      " 14  indy_hist_macd110-440   70693 non-null  float64\n",
      " 15  indy_rsi25-ma20         70693 non-null  float64\n",
      " 16  indy_6ATRTrail_DC-110   70693 non-null  float64\n",
      " 17  cate_3trend-550_ma110   70693 non-null  int64  \n",
      " 18  cate_2trend-1100_ma220  70693 non-null  int64  \n",
      " 19  cate_rannkHL1100-ma66   70693 non-null  int64  \n",
      " 20  cate_CombineTrend       70693 non-null  int64  \n",
      " 21  LongSignal              70693 non-null  int64  \n",
      "dtypes: float64(17), int64(5)\n",
      "memory usage: 12.4 MB\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "dataframe = pandas.read_csv(filepath,index_col=\"datetime\", parse_dates=['datetime'],dayfirst=True)\n",
    "\n",
    "print(dataframe.shape)\n",
    "              \n",
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 70693 entries, 2007-01-03 09:45:00 to 2020-06-10 16:45:00\n",
      "Data columns (total 18 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   indy_ma-550             70693 non-null  float64\n",
      " 1   indy_ma-1100            70693 non-null  float64\n",
      " 2   indy_hh-550             70693 non-null  float64\n",
      " 3   indy_ll-550             70693 non-null  float64\n",
      " 4   indy_mid-550            70693 non-null  float64\n",
      " 5   indy_hh2-1100           70693 non-null  float64\n",
      " 6   indy_ll2-1100           70693 non-null  float64\n",
      " 7   indy_mid2-1100          70693 non-null  float64\n",
      " 8   indy_macd110-440        70693 non-null  float64\n",
      " 9   indy_signal110-440-110  70693 non-null  float64\n",
      " 10  indy_hist_macd110-440   70693 non-null  float64\n",
      " 11  indy_rsi25-ma20         70693 non-null  float64\n",
      " 12  indy_6ATRTrail_DC-110   70693 non-null  float64\n",
      " 13  cate_3trend-550_ma110   70693 non-null  int64  \n",
      " 14  cate_2trend-1100_ma220  70693 non-null  int64  \n",
      " 15  cate_rannkHL1100-ma66   70693 non-null  int64  \n",
      " 16  cate_CombineTrend       70693 non-null  int64  \n",
      " 17  LongSignal              70693 non-null  int64  \n",
      "dtypes: float64(13), int64(5)\n",
      "memory usage: 10.2 MB\n"
     ]
    }
   ],
   "source": [
    "df=dataframe[st:ed]\n",
    "#dfOHLC=df.loc[:,['open','high','low','close']]\n",
    "df.drop(columns=['open','high','low','close'],inplace=True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LongSignal'"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelName=df.columns[-1]\n",
    "labelName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df=df.drop(columns=labelName)\n",
    "y_df=df[labelName]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 70693 entries, 2007-01-03 09:45:00 to 2020-06-10 16:45:00\n",
      "Data columns (total 17 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   indy_ma-550             70693 non-null  float64\n",
      " 1   indy_ma-1100            70693 non-null  float64\n",
      " 2   indy_hh-550             70693 non-null  float64\n",
      " 3   indy_ll-550             70693 non-null  float64\n",
      " 4   indy_mid-550            70693 non-null  float64\n",
      " 5   indy_hh2-1100           70693 non-null  float64\n",
      " 6   indy_ll2-1100           70693 non-null  float64\n",
      " 7   indy_mid2-1100          70693 non-null  float64\n",
      " 8   indy_macd110-440        70693 non-null  float64\n",
      " 9   indy_signal110-440-110  70693 non-null  float64\n",
      " 10  indy_hist_macd110-440   70693 non-null  float64\n",
      " 11  indy_rsi25-ma20         70693 non-null  float64\n",
      " 12  indy_6ATRTrail_DC-110   70693 non-null  float64\n",
      " 13  cate_3trend-550_ma110   70693 non-null  int64  \n",
      " 14  cate_2trend-1100_ma220  70693 non-null  int64  \n",
      " 15  cate_rannkHL1100-ma66   70693 non-null  int64  \n",
      " 16  cate_CombineTrend       70693 non-null  int64  \n",
      "dtypes: float64(13), int64(4)\n",
      "memory usage: 9.7 MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indy_ma-550</th>\n",
       "      <th>indy_ma-1100</th>\n",
       "      <th>indy_hh-550</th>\n",
       "      <th>indy_ll-550</th>\n",
       "      <th>indy_mid-550</th>\n",
       "      <th>indy_hh2-1100</th>\n",
       "      <th>indy_ll2-1100</th>\n",
       "      <th>indy_mid2-1100</th>\n",
       "      <th>indy_macd110-440</th>\n",
       "      <th>indy_signal110-440-110</th>\n",
       "      <th>indy_hist_macd110-440</th>\n",
       "      <th>indy_rsi25-ma20</th>\n",
       "      <th>indy_6ATRTrail_DC-110</th>\n",
       "      <th>cate_3trend-550_ma110</th>\n",
       "      <th>cate_2trend-1100_ma220</th>\n",
       "      <th>cate_rannkHL1100-ma66</th>\n",
       "      <th>cate_CombineTrend</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-06-10 16:15:00</th>\n",
       "      <td>887.68</td>\n",
       "      <td>847.74</td>\n",
       "      <td>977.9</td>\n",
       "      <td>834.2</td>\n",
       "      <td>906.05</td>\n",
       "      <td>977.9</td>\n",
       "      <td>715.3</td>\n",
       "      <td>846.6</td>\n",
       "      <td>56.43</td>\n",
       "      <td>41.48</td>\n",
       "      <td>14.95</td>\n",
       "      <td>46.25</td>\n",
       "      <td>952.82</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-10 16:30:00</th>\n",
       "      <td>887.85</td>\n",
       "      <td>847.94</td>\n",
       "      <td>977.9</td>\n",
       "      <td>834.2</td>\n",
       "      <td>906.05</td>\n",
       "      <td>977.9</td>\n",
       "      <td>715.3</td>\n",
       "      <td>846.6</td>\n",
       "      <td>56.54</td>\n",
       "      <td>41.78</td>\n",
       "      <td>14.76</td>\n",
       "      <td>46.64</td>\n",
       "      <td>952.65</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-10 16:45:00</th>\n",
       "      <td>888.02</td>\n",
       "      <td>848.15</td>\n",
       "      <td>977.9</td>\n",
       "      <td>834.2</td>\n",
       "      <td>906.05</td>\n",
       "      <td>977.9</td>\n",
       "      <td>715.3</td>\n",
       "      <td>846.6</td>\n",
       "      <td>56.64</td>\n",
       "      <td>42.07</td>\n",
       "      <td>14.57</td>\n",
       "      <td>47.13</td>\n",
       "      <td>952.71</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     indy_ma-550  indy_ma-1100  indy_hh-550  indy_ll-550  \\\n",
       "datetime                                                                   \n",
       "2020-06-10 16:15:00       887.68        847.74        977.9        834.2   \n",
       "2020-06-10 16:30:00       887.85        847.94        977.9        834.2   \n",
       "2020-06-10 16:45:00       888.02        848.15        977.9        834.2   \n",
       "\n",
       "                     indy_mid-550  indy_hh2-1100  indy_ll2-1100  \\\n",
       "datetime                                                          \n",
       "2020-06-10 16:15:00        906.05          977.9          715.3   \n",
       "2020-06-10 16:30:00        906.05          977.9          715.3   \n",
       "2020-06-10 16:45:00        906.05          977.9          715.3   \n",
       "\n",
       "                     indy_mid2-1100  indy_macd110-440  indy_signal110-440-110  \\\n",
       "datetime                                                                        \n",
       "2020-06-10 16:15:00           846.6             56.43                   41.48   \n",
       "2020-06-10 16:30:00           846.6             56.54                   41.78   \n",
       "2020-06-10 16:45:00           846.6             56.64                   42.07   \n",
       "\n",
       "                     indy_hist_macd110-440  indy_rsi25-ma20  \\\n",
       "datetime                                                      \n",
       "2020-06-10 16:15:00                  14.95            46.25   \n",
       "2020-06-10 16:30:00                  14.76            46.64   \n",
       "2020-06-10 16:45:00                  14.57            47.13   \n",
       "\n",
       "                     indy_6ATRTrail_DC-110  cate_3trend-550_ma110  \\\n",
       "datetime                                                            \n",
       "2020-06-10 16:15:00                 952.82                      3   \n",
       "2020-06-10 16:30:00                 952.65                      3   \n",
       "2020-06-10 16:45:00                 952.71                      3   \n",
       "\n",
       "                     cate_2trend-1100_ma220  cate_rannkHL1100-ma66  \\\n",
       "datetime                                                             \n",
       "2020-06-10 16:15:00                       1                      4   \n",
       "2020-06-10 16:30:00                       1                      4   \n",
       "2020-06-10 16:45:00                       1                      4   \n",
       "\n",
       "                     cate_CombineTrend  \n",
       "datetime                                \n",
       "2020-06-10 16:15:00                  4  \n",
       "2020-06-10 16:30:00                  4  \n",
       "2020-06-10 16:45:00                  4  "
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_df.info())\n",
    "X_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime\n",
       "2020-06-10 15:45:00    1\n",
       "2020-06-10 16:00:00    1\n",
       "2020-06-10 16:15:00    1\n",
       "2020-06-10 16:30:00    1\n",
       "2020-06-10 16:45:00    1\n",
       "Name: LongSignal, dtype: int64"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input (X) and output (Y) variables\n",
    "X = X_df.to_numpy()\n",
    "y =y_df.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from keras.utils import to_categorical\n",
    "if True :\n",
    " encoder = LabelEncoder()\n",
    " encoder.fit(y)\n",
    " y = encoder.transform(y)\n",
    " # convert integers to dummy variables (i.e. one hot encoded)\n",
    " y = to_categorical(y)\n",
    "\n",
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70693, 17)\n",
      "(70693, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1=17\n",
    "h2=17\n",
    "h3=0\n",
    "\n",
    "input_n=X.shape[1]\n",
    "\n",
    "xpoch=105\n",
    "xbatch=32\n",
    "\n",
    "#my_kernelInit='he_uniform'\n",
    "#kernel_initializer=\"glorot_uniform\"  #default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BasicModel():\n",
    "\n",
    "  model = Sequential()  \n",
    "  \n",
    "  model.add(Dense(h1, input_dim=X.shape[1], kernel_initializer='he_normal',activation='relu' ))\n",
    "  model.add(Dense(h2, kernel_initializer='he_normal',activation='relu'))\n",
    "\n",
    "  \n",
    "  model.add(Dense(1,  activation='sigmoid'))\n",
    "  \n",
    "    # Compile model\n",
    "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "  return model  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelByAllTuning():\n",
    "    model_x=Sequential()\n",
    "    \n",
    "    param_dropout=0.02\n",
    "    vaMaxNorm_WC=4\n",
    "    \n",
    "    #l2_val=0.01 #0.865 vs 0.851\n",
    "    l2_val=0.00100000 #0.93 vs 0.84\n",
    "    \n",
    "     #input\n",
    "    model_x.add(Dropout(param_dropout, input_shape=(input_n,)))\n",
    "    \n",
    "    #layer#1\n",
    "    model_x.add(Dense(h1, activation=\"relu\", kernel_constraint=maxnorm(vaMaxNorm_WC),kernel_regularizer=l2(l2_val)))\n",
    "    model_x.add(Dropout(param_dropout))\n",
    "    \n",
    "    #layer#2\n",
    "    model_x.add(Dense(h2, activation=\"relu\", kernel_constraint=maxnorm(vaMaxNorm_WC),kernel_regularizer=l2(l2_val)))\n",
    "    model_x.add(Dropout(param_dropout))\n",
    "    \n",
    "\n",
    "    #model_x.add(Dense(1, activation=\"sigmoid\"))\n",
    "    #model_x.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    model_x.add(Dense(2, activation='softmax'))\n",
    "    model_x.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreatePipeLine(fn,n_epochs,n_batch_size):\n",
    " #early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=1, verbose=0, mode='auto')\n",
    " estimator_steps=[]\n",
    " #estimator_steps.append(('standardize', StandardScaler()))\n",
    " estimator_steps.append(('minmax_range', MinMaxScaler()))\n",
    " #print('Select Model funciton: ',fn)\n",
    " estimator_steps.append(('mlp', KerasClassifier(build_fn=fn, epochs=n_epochs, batch_size=n_batch_size)))\n",
    "\n",
    " xpipeline=Pipeline(estimator_steps)\n",
    " return xpipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xsplits=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train from  2007-01-03 09:45:00  to test as follows\n",
      "test from  2009-04-17 10:30:00\n",
      "test from  2011-08-11 15:45:00\n",
      "test from  2013-11-20 12:15:00\n",
      "test from  2016-02-10 09:45:00\n",
      "test from  2018-04-05 15:30:00\n"
     ]
    }
   ],
   "source": [
    "option=2\n",
    "if option==1:\n",
    " #xfold = StratifiedKFold(n_splits=xsplits, shuffle=True, random_state=xseed)\n",
    " xfold = KFold(n_splits=xsplits, shuffle=True, random_state=xseed)\n",
    "else :\n",
    " \n",
    " xfold = TimeSeriesSplit(n_splits=xsplits,max_train_size=None)\n",
    " df_Xtime=(X_df.reset_index())[['datetime']]\n",
    " print('train from ',df_Xtime.loc[0,'datetime'] ,' to test as follows')\n",
    " for train, test in xfold.split(X_df):\n",
    "  print('test from ',df_Xtime.loc[test[0],'datetime']) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/105\n",
      "11783/11783 [==============================] - 1s 56us/step - loss: 0.3769 - accuracy: 0.8494\n",
      "Epoch 2/105\n",
      "11783/11783 [==============================] - 0s 37us/step - loss: 0.2414 - accuracy: 0.9084\n",
      "Epoch 3/105\n",
      "11783/11783 [==============================] - 0s 37us/step - loss: 0.2162 - accuracy: 0.9152\n",
      "Epoch 4/105\n",
      "11783/11783 [==============================] - 0s 38us/step - loss: 0.2038 - accuracy: 0.9187 0s - loss: 0.2072 - ac\n",
      "Epoch 5/105\n",
      "11783/11783 [==============================] - 0s 38us/step - loss: 0.1916 - accuracy: 0.9209\n",
      "Epoch 6/105\n",
      "11783/11783 [==============================] - 0s 37us/step - loss: 0.1890 - accuracy: 0.9208\n",
      "Epoch 7/105\n",
      "11783/11783 [==============================] - 0s 39us/step - loss: 0.1789 - accuracy: 0.9276 0s - loss: 0.1816 - ac\n",
      "Epoch 8/105\n",
      "11783/11783 [==============================] - 0s 38us/step - loss: 0.1753 - accuracy: 0.9293\n",
      "Epoch 9/105\n",
      "11783/11783 [==============================] - 0s 38us/step - loss: 0.1768 - accuracy: 0.9289\n",
      "Epoch 10/105\n",
      "11783/11783 [==============================] - 0s 38us/step - loss: 0.1650 - accuracy: 0.9356 0s - loss: 0.1623 - accu\n",
      "Epoch 11/105\n",
      "11783/11783 [==============================] - 0s 40us/step - loss: 0.1645 - accuracy: 0.9357\n",
      "Epoch 12/105\n",
      "11783/11783 [==============================] - 0s 38us/step - loss: 0.1657 - accuracy: 0.9361 0s - loss: 0.1654 - accuracy: 0.\n",
      "Epoch 13/105\n",
      "11783/11783 [==============================] - 0s 38us/step - loss: 0.1639 - accuracy: 0.9384 0s - loss: 0.1691 - accura - ETA: 0s - loss: 0.1618 - accuracy: 0.\n",
      "Epoch 14/105\n",
      "11783/11783 [==============================] - 0s 36us/step - loss: 0.1611 - accuracy: 0.9397\n",
      "Epoch 15/105\n",
      "11783/11783 [==============================] - 0s 41us/step - loss: 0.1547 - accuracy: 0.9400 0s - loss: 0.1583 - \n",
      "Epoch 16/105\n",
      "11783/11783 [==============================] - 0s 36us/step - loss: 0.1536 - accuracy: 0.9422\n",
      "Epoch 17/105\n",
      "11783/11783 [==============================] - 0s 36us/step - loss: 0.1530 - accuracy: 0.9426\n",
      "Epoch 18/105\n",
      "11783/11783 [==============================] - 0s 36us/step - loss: 0.1505 - accuracy: 0.9430\n",
      "Epoch 19/105\n",
      "11783/11783 [==============================] - 0s 37us/step - loss: 0.1509 - accuracy: 0.9445\n",
      "Epoch 20/105\n",
      "11783/11783 [==============================] - 0s 36us/step - loss: 0.1449 - accuracy: 0.9459 0s - loss: 0.1392 - \n",
      "Epoch 21/105\n",
      "11783/11783 [==============================] - 0s 36us/step - loss: 0.1453 - accuracy: 0.9463\n",
      "Epoch 22/105\n",
      "11783/11783 [==============================] - 0s 37us/step - loss: 0.1524 - accuracy: 0.9457\n",
      "Epoch 23/105\n",
      "11783/11783 [==============================] - 0s 37us/step - loss: 0.1432 - accuracy: 0.9487\n",
      "Epoch 24/105\n",
      "11783/11783 [==============================] - 0s 36us/step - loss: 0.1417 - accuracy: 0.9478\n",
      "Epoch 25/105\n",
      "11783/11783 [==============================] - 0s 36us/step - loss: 0.1425 - accuracy: 0.9504\n",
      "Epoch 26/105\n",
      "11783/11783 [==============================] - ETA: 0s - loss: 0.1400 - accuracy: 0.9490 ETA: 0s - loss: 0.1389 - ac - 0s 37us/step - loss: 0.1406 - accuracy: 0.9491\n",
      "Epoch 27/105\n",
      "11783/11783 [==============================] - 0s 37us/step - loss: 0.1391 - accuracy: 0.9480 0s - loss: 0.1379 - accuracy: 0.\n",
      "Epoch 28/105\n",
      "11783/11783 [==============================] - 0s 37us/step - loss: 0.1345 - accuracy: 0.9519\n",
      "Epoch 29/105\n",
      "11783/11783 [==============================] - 0s 37us/step - loss: 0.1325 - accuracy: 0.9534\n",
      "Epoch 30/105\n",
      "11783/11783 [==============================] - 0s 37us/step - loss: 0.1368 - accuracy: 0.9527 0s - loss: 0.1331 - \n",
      "Epoch 31/105\n",
      "11783/11783 [==============================] - 0s 36us/step - loss: 0.1354 - accuracy: 0.9518\n",
      "Epoch 32/105\n",
      "11783/11783 [==============================] - 0s 37us/step - loss: 0.1330 - accuracy: 0.9513 0s - loss: 0.1314 - accuracy: \n",
      "Epoch 33/105\n",
      "11783/11783 [==============================] - 0s 37us/step - loss: 0.1303 - accuracy: 0.9541 0s - loss: 0.1288 - \n",
      "Epoch 34/105\n",
      "11783/11783 [==============================] - 0s 37us/step - loss: 0.1318 - accuracy: 0.9554\n",
      "Epoch 35/105\n",
      "11783/11783 [==============================] - 0s 37us/step - loss: 0.1313 - accuracy: 0.9544\n",
      "Epoch 36/105\n",
      "11783/11783 [==============================] - 0s 37us/step - loss: 0.1298 - accuracy: 0.9550\n",
      "Epoch 37/105\n",
      "11783/11783 [==============================] - 0s 38us/step - loss: 0.1269 - accuracy: 0.9551\n",
      "Epoch 38/105\n",
      "11783/11783 [==============================] - 0s 37us/step - loss: 0.1279 - accuracy: 0.9567 0s - loss: 0.1300 - accuracy: 0.\n",
      "Epoch 39/105\n",
      "11783/11783 [==============================] - 0s 36us/step - loss: 0.1318 - accuracy: 0.9537 0s - loss: 0.1316 - accuracy: 0.\n",
      "Epoch 40/105\n",
      "11783/11783 [==============================] - 0s 36us/step - loss: 0.1250 - accuracy: 0.9569 0s - loss: 0.1208 - ac\n",
      "Epoch 41/105\n",
      "11783/11783 [==============================] - 0s 36us/step - loss: 0.1225 - accuracy: 0.9585\n",
      "Epoch 42/105\n",
      "11783/11783 [==============================] - 0s 37us/step - loss: 0.1208 - accuracy: 0.9591\n",
      "Epoch 43/105\n",
      "11783/11783 [==============================] - 0s 37us/step - loss: 0.1178 - accuracy: 0.9599\n",
      "Epoch 44/105\n",
      "11783/11783 [==============================] - 0s 37us/step - loss: 0.1194 - accuracy: 0.9587 0s - loss: 0.1187 - accu\n",
      "Epoch 45/105\n",
      "11783/11783 [==============================] - 0s 37us/step - loss: 0.1192 - accuracy: 0.9579\n",
      "Epoch 46/105\n",
      "11783/11783 [==============================] - 0s 37us/step - loss: 0.1192 - accuracy: 0.9610\n",
      "Epoch 47/105\n",
      "11783/11783 [==============================] - 0s 37us/step - loss: 0.1209 - accuracy: 0.9599\n",
      "Epoch 48/105\n",
      "11783/11783 [==============================] - 0s 37us/step - loss: 0.1171 - accuracy: 0.9620\n",
      "Epoch 49/105\n",
      "11783/11783 [==============================] - 0s 36us/step - loss: 0.1168 - accuracy: 0.9610\n",
      "Epoch 50/105\n",
      "11783/11783 [==============================] - 0s 37us/step - loss: 0.1137 - accuracy: 0.9633 0s - loss: 0.1086 - accuracy\n",
      "Epoch 51/105\n",
      "11783/11783 [==============================] - 0s 37us/step - loss: 0.1165 - accuracy: 0.9616 0s - loss: 0.1204 - accu - ETA: 0s - loss: 0.1161 - accuracy: 0.96\n",
      "Epoch 52/105\n",
      "11783/11783 [==============================] - 0s 36us/step - loss: 0.1147 - accuracy: 0.9624\n",
      "Epoch 53/105\n",
      "11783/11783 [==============================] - 0s 36us/step - loss: 0.1160 - accuracy: 0.9626\n",
      "Epoch 54/105\n",
      "11783/11783 [==============================] - 0s 36us/step - loss: 0.1095 - accuracy: 0.9650\n",
      "Epoch 55/105\n",
      "11783/11783 [==============================] - 0s 36us/step - loss: 0.1101 - accuracy: 0.9635\n",
      "Epoch 56/105\n",
      "11783/11783 [==============================] - 0s 36us/step - loss: 0.1096 - accuracy: 0.9644 0s - loss: 0.1160 - accuracy\n",
      "Epoch 57/105\n",
      "11783/11783 [==============================] - 0s 36us/step - loss: 0.1132 - accuracy: 0.9628\n",
      "Epoch 58/105\n",
      "11783/11783 [==============================] - 0s 36us/step - loss: 0.1128 - accuracy: 0.9628\n",
      "Epoch 59/105\n",
      "11783/11783 [==============================] - 0s 36us/step - loss: 0.1142 - accuracy: 0.9608\n",
      "Epoch 60/105\n",
      "11783/11783 [==============================] - 0s 36us/step - loss: 0.1067 - accuracy: 0.9666\n",
      "Epoch 61/105\n",
      "11783/11783 [==============================] - 0s 36us/step - loss: 0.1106 - accuracy: 0.9661\n",
      "Epoch 62/105\n",
      "11783/11783 [==============================] - 0s 36us/step - loss: 0.1072 - accuracy: 0.9656\n",
      "Epoch 63/105\n",
      "11783/11783 [==============================] - 0s 36us/step - loss: 0.1042 - accuracy: 0.9670\n",
      "Epoch 64/105\n",
      "11783/11783 [==============================] - 0s 36us/step - loss: 0.1041 - accuracy: 0.9662\n",
      "Epoch 65/105\n",
      "11783/11783 [==============================] - 0s 36us/step - loss: 0.1006 - accuracy: 0.9683\n",
      "Epoch 66/105\n",
      "11783/11783 [==============================] - 0s 36us/step - loss: 0.1068 - accuracy: 0.9676\n",
      "Epoch 67/105\n",
      "11783/11783 [==============================] - 0s 36us/step - loss: 0.1018 - accuracy: 0.9693\n",
      "Epoch 68/105\n",
      "11783/11783 [==============================] - 0s 36us/step - loss: 0.1074 - accuracy: 0.9669\n",
      "Epoch 69/105\n",
      "11783/11783 [==============================] - 0s 36us/step - loss: 0.1032 - accuracy: 0.9709\n",
      "Epoch 70/105\n",
      "11783/11783 [==============================] - 0s 36us/step - loss: 0.0998 - accuracy: 0.9717\n",
      "Epoch 71/105\n",
      "11783/11783 [==============================] - 0s 35us/step - loss: 0.1072 - accuracy: 0.9670\n",
      "Epoch 72/105\n",
      "11783/11783 [==============================] - 0s 35us/step - loss: 0.1060 - accuracy: 0.9672\n",
      "Epoch 73/105\n",
      "11783/11783 [==============================] - 0s 35us/step - loss: 0.0998 - accuracy: 0.9726\n",
      "Epoch 74/105\n",
      "11783/11783 [==============================] - 0s 36us/step - loss: 0.0969 - accuracy: 0.9697\n",
      "Epoch 75/105\n",
      "11783/11783 [==============================] - 0s 35us/step - loss: 0.1013 - accuracy: 0.9679\n",
      "Epoch 76/105\n",
      "11783/11783 [==============================] - 0s 35us/step - loss: 0.0973 - accuracy: 0.9712 0s - loss: 0.0967 - accuracy\n",
      "Epoch 77/105\n",
      "11783/11783 [==============================] - 0s 35us/step - loss: 0.0939 - accuracy: 0.9722\n",
      "Epoch 78/105\n",
      "11783/11783 [==============================] - 0s 35us/step - loss: 0.0940 - accuracy: 0.9736\n",
      "Epoch 79/105\n",
      "11783/11783 [==============================] - 0s 35us/step - loss: 0.0927 - accuracy: 0.9724\n",
      "Epoch 80/105\n",
      "11783/11783 [==============================] - 0s 35us/step - loss: 0.0966 - accuracy: 0.9715\n",
      "Epoch 81/105\n",
      "11783/11783 [==============================] - 0s 35us/step - loss: 0.0946 - accuracy: 0.9732\n",
      "Epoch 82/105\n",
      "11783/11783 [==============================] - 0s 35us/step - loss: 0.0971 - accuracy: 0.9734\n",
      "Epoch 83/105\n",
      "11783/11783 [==============================] - 0s 35us/step - loss: 0.0935 - accuracy: 0.9750\n",
      "Epoch 84/105\n",
      "11783/11783 [==============================] - 0s 35us/step - loss: 0.0981 - accuracy: 0.9715 0s - loss: 0.0981 - accuracy: \n",
      "Epoch 85/105\n",
      "11783/11783 [==============================] - 0s 35us/step - loss: 0.0894 - accuracy: 0.9747\n",
      "Epoch 86/105\n",
      "11783/11783 [==============================] - 0s 35us/step - loss: 0.0985 - accuracy: 0.9714\n",
      "Epoch 87/105\n",
      "11783/11783 [==============================] - 0s 35us/step - loss: 0.0882 - accuracy: 0.9738\n",
      "Epoch 88/105\n",
      "11783/11783 [==============================] - 0s 35us/step - loss: 0.0937 - accuracy: 0.9733\n",
      "Epoch 89/105\n",
      "11783/11783 [==============================] - 0s 35us/step - loss: 0.0939 - accuracy: 0.9717\n",
      "Epoch 90/105\n",
      "11783/11783 [==============================] - 0s 35us/step - loss: 0.0915 - accuracy: 0.9751\n",
      "Epoch 91/105\n",
      "11783/11783 [==============================] - 0s 35us/step - loss: 0.0928 - accuracy: 0.9720\n",
      "Epoch 92/105\n",
      "11783/11783 [==============================] - 0s 35us/step - loss: 0.0905 - accuracy: 0.9734\n",
      "Epoch 93/105\n",
      "11783/11783 [==============================] - 0s 35us/step - loss: 0.0870 - accuracy: 0.9764\n",
      "Epoch 94/105\n",
      "11783/11783 [==============================] - 0s 35us/step - loss: 0.0900 - accuracy: 0.9750\n",
      "Epoch 95/105\n",
      "11783/11783 [==============================] - 0s 35us/step - loss: 0.0907 - accuracy: 0.9743\n",
      "Epoch 96/105\n",
      "11783/11783 [==============================] - 0s 35us/step - loss: 0.0885 - accuracy: 0.9759\n",
      "Epoch 97/105\n",
      "11783/11783 [==============================] - 0s 35us/step - loss: 0.0867 - accuracy: 0.9773\n",
      "Epoch 98/105\n",
      "11783/11783 [==============================] - 0s 36us/step - loss: 0.0924 - accuracy: 0.9749\n",
      "Epoch 99/105\n",
      "11783/11783 [==============================] - 0s 35us/step - loss: 0.0892 - accuracy: 0.9747\n",
      "Epoch 100/105\n",
      "11783/11783 [==============================] - 0s 35us/step - loss: 0.0898 - accuracy: 0.9755\n",
      "Epoch 101/105\n",
      "11783/11783 [==============================] - 0s 35us/step - loss: 0.0914 - accuracy: 0.9751\n",
      "Epoch 102/105\n",
      "11783/11783 [==============================] - 0s 35us/step - loss: 0.0908 - accuracy: 0.9745\n",
      "Epoch 103/105\n",
      "11783/11783 [==============================] - 0s 36us/step - loss: 0.0883 - accuracy: 0.9758\n",
      "Epoch 104/105\n",
      "11783/11783 [==============================] - 0s 35us/step - loss: 0.0875 - accuracy: 0.9770\n",
      "Epoch 105/105\n",
      "11783/11783 [==============================] - 0s 35us/step - loss: 0.0878 - accuracy: 0.9785\n",
      "11782/11782 [==============================] - 0s 30us/step\n",
      "Epoch 1/105\n",
      "23565/23565 [==============================] - 1s 46us/step - loss: 0.4505 - accuracy: 0.8067\n",
      "Epoch 2/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.3355 - accuracy: 0.8612 0s - loss: 0.3648 - accura - ETA: 0s - loss: 0.346\n",
      "Epoch 3/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.3124 - accuracy: 0.8710\n",
      "Epoch 4/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.2993 - accuracy: 0.8762\n",
      "Epoch 5/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.2898 - accuracy: 0.8785\n",
      "Epoch 6/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.2791 - accuracy: 0.8843\n",
      "Epoch 7/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.2762 - accuracy: 0.8872\n",
      "Epoch 8/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.2745 - accuracy: 0.8900 0s - loss: 0\n",
      "Epoch 9/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.2690 - accuracy: 0.8897\n",
      "Epoch 10/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.2649 - accuracy: 0.8930 0s - loss: 0.264\n",
      "Epoch 11/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.2633 - accuracy: 0.8919\n",
      "Epoch 12/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.2632 - accuracy: 0.8931\n",
      "Epoch 13/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.2596 - accuracy: 0.8940 0s - loss: 0.2591 - accura\n",
      "Epoch 14/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.2491 - accuracy: 0.9004 0s - loss: 0.2504 - accuracy: \n",
      "Epoch 15/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.2461 - accuracy: 0.9018\n",
      "Epoch 16/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.2453 - accuracy: 0.9013 0s - loss: 0.2540  - ETA: 0s - loss: 0.2457 - accuracy: 0.\n",
      "Epoch 17/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.2416 - accuracy: 0.9043\n",
      "Epoch 18/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.2376 - accuracy: 0.9056\n",
      "Epoch 19/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.2357 - accuracy: 0.9062 0s - loss: 0.2405 - accuracy - ETA: 0s - loss: 0.2417 - ac\n",
      "Epoch 20/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.2294 - accuracy: 0.9078 0s - loss: 0.2301 - accuracy\n",
      "Epoch 21/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.2289 - accuracy: 0.9113\n",
      "Epoch 22/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.2281 - accuracy: 0.9095\n",
      "Epoch 23/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.2219 - accuracy: 0.9135 0s - loss: 0.2\n",
      "Epoch 24/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.2197 - accuracy: 0.9136 0s - loss: 0.2202 - accuracy: \n",
      "Epoch 25/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.2210 - accuracy: 0.9126\n",
      "Epoch 26/105\n",
      "23565/23565 [==============================] - ETA: 0s - loss: 0.2194 - accuracy: 0.91 - 1s 36us/step - loss: 0.2205 - accuracy: 0.9131\n",
      "Epoch 27/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.2191 - accuracy: 0.9161 0s - los\n",
      "Epoch 28/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.2181 - accuracy: 0.9142 0s - loss: 0.2144 \n",
      "Epoch 29/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.2137 - accuracy: 0.9170\n",
      "Epoch 30/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.2142 - accuracy: 0.9174\n",
      "Epoch 31/105\n",
      "23565/23565 [==============================] - ETA: 0s - loss: 0.2168 - accuracy: 0.91 - 1s 36us/step - loss: 0.2160 - accuracy: 0.9162\n",
      "Epoch 32/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.2159 - accuracy: 0.9167\n",
      "Epoch 33/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.2137 - accuracy: 0.9170\n",
      "Epoch 34/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.2124 - accuracy: 0.9169 0s - loss: 0.2125 - accuracy: \n",
      "Epoch 35/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.2077 - accuracy: 0.9203\n",
      "Epoch 36/105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23565/23565 [==============================] - 1s 38us/step - loss: 0.2085 - accuracy: 0.9193 0s - loss: 0.2\n",
      "Epoch 37/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.2086 - accuracy: 0.9207\n",
      "Epoch 38/105\n",
      "23565/23565 [==============================] - ETA: 0s - loss: 0.2038 - accuracy: 0.92 - 1s 36us/step - loss: 0.2041 - accuracy: 0.9222\n",
      "Epoch 39/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.2079 - accuracy: 0.9212 0s - loss: 0\n",
      "Epoch 40/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.2051 - accuracy: 0.9230\n",
      "Epoch 41/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.2049 - accuracy: 0.9218\n",
      "Epoch 42/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.2039 - accuracy: 0.9239\n",
      "Epoch 43/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.2025 - accuracy: 0.9231\n",
      "Epoch 44/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.2036 - accuracy: 0.9221 0s - loss: 0.202\n",
      "Epoch 45/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.2020 - accuracy: 0.9230 0s - l\n",
      "Epoch 46/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.1993 - accuracy: 0.9246\n",
      "Epoch 47/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.2000 - accuracy: 0.9248 0s - loss: 0.1988 -  - ETA: 0s - loss: 0.2004 - accuracy: \n",
      "Epoch 48/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.2018 - accuracy: 0.9227 0s - loss: 0.2003 - accuracy - ETA: 0s - loss: 0.2006 - accuracy: 0.\n",
      "Epoch 49/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.1972 - accuracy: 0.9265\n",
      "Epoch 50/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.1968 - accuracy: 0.9248 0s - loss: 0.1980 - accuracy: 0.92\n",
      "Epoch 51/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.1985 - accuracy: 0.9248\n",
      "Epoch 52/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.1972 - accuracy: 0.9255\n",
      "Epoch 53/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.1971 - accuracy: 0.9259\n",
      "Epoch 54/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.1937 - accuracy: 0.9258\n",
      "Epoch 55/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.1955 - accuracy: 0.9272\n",
      "Epoch 56/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.1947 - accuracy: 0.9281 0s - loss: 0.1944 - accuracy - ETA: 0s - loss: 0.1956 - accura\n",
      "Epoch 57/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.1916 - accuracy: 0.9295\n",
      "Epoch 58/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.1953 - accuracy: 0.9265 0s - loss: 0.1956 - ac\n",
      "Epoch 59/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.1925 - accuracy: 0.9292 0s - loss: 0.1\n",
      "Epoch 60/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.1879 - accuracy: 0.9313\n",
      "Epoch 61/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.1922 - accuracy: 0.9289 0s - loss:\n",
      "Epoch 62/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.1910 - accuracy: 0.9300 0s - loss: 0.1903 - accuracy\n",
      "Epoch 63/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.1908 - accuracy: 0.9302 0s - loss: 0.1943 \n",
      "Epoch 64/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.1905 - accuracy: 0.9300\n",
      "Epoch 65/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.1911 - accuracy: 0.9302 0s - loss: 0.1964 - accu\n",
      "Epoch 66/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.1910 - accuracy: 0.9293 0s - loss: 0.1975 -  - ETA: 0s - loss: 0.1949 - accuracy - ETA: 0s - loss: 0.1905 - accuracy: \n",
      "Epoch 67/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.1894 - accuracy: 0.9302\n",
      "Epoch 68/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.1844 - accuracy: 0.9321 0s - loss: 0.1\n",
      "Epoch 69/105\n",
      "23565/23565 [==============================] - 1s 39us/step - loss: 0.1852 - accuracy: 0.9322\n",
      "Epoch 70/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.1879 - accuracy: 0.9324 0s - loss: 0.1889 - accuracy: 0.\n",
      "Epoch 71/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.1865 - accuracy: 0.9310 0s - loss: 0.1875 - accuracy: 0.\n",
      "Epoch 72/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.1841 - accuracy: 0.9344\n",
      "Epoch 73/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.1843 - accuracy: 0.9325\n",
      "Epoch 74/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.1854 - accuracy: 0.9333 0s - loss: 0.1818 - accuracy\n",
      "Epoch 75/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.1867 - accuracy: 0.9319 0s - loss: 0.1861 - accuracy: 0.93\n",
      "Epoch 76/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.1852 - accuracy: 0.9330\n",
      "Epoch 77/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.1833 - accuracy: 0.9329 0s - loss: 0.1822 - accu\n",
      "Epoch 78/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.1837 - accuracy: 0.9331\n",
      "Epoch 79/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.1832 - accuracy: 0.9335 0s\n",
      "Epoch 80/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.1840 - accuracy: 0.9363 0s - loss: 0.1 - ETA: 0s - loss: 0.1830 - accuracy: 0.\n",
      "Epoch 81/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.1812 - accuracy: 0.9350 0s - loss: 0.1837 - ac\n",
      "Epoch 82/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.1794 - accuracy: 0.9355 0s - loss: 0.1835 - accu\n",
      "Epoch 83/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.1833 - accuracy: 0.9321\n",
      "Epoch 84/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.1771 - accuracy: 0.9380 0s - loss: 0.1774 - accuracy: 0.\n",
      "Epoch 85/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.1829 - accuracy: 0.9332\n",
      "Epoch 86/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.1807 - accuracy: 0.9342 0s - loss: 0.1794 - ac - ETA: 0s - loss: 0.1814 - accu\n",
      "Epoch 87/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.1780 - accuracy: 0.9343 0s - loss: 0.1809 - \n",
      "Epoch 88/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.1835 - accuracy: 0.9330\n",
      "Epoch 89/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.1783 - accuracy: 0.9356 0s - loss: 0\n",
      "Epoch 90/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.1776 - accuracy: 0.9358\n",
      "Epoch 91/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.1801 - accuracy: 0.9337 0s - loss: 0.1834 - accuracy: \n",
      "Epoch 92/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.1753 - accuracy: 0.9372 0s - loss: 0.1777 - \n",
      "Epoch 93/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.1749 - accuracy: 0.9375 0s - loss: 0.1732 - accuracy - ETA: 0s - loss: 0.1745 - accuracy\n",
      "Epoch 94/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.1735 - accuracy: 0.9379\n",
      "Epoch 95/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.1776 - accuracy: 0.9349 0s - loss: 0.1798 - accura\n",
      "Epoch 96/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.1793 - accuracy: 0.9346\n",
      "Epoch 97/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.1766 - accuracy: 0.9373\n",
      "Epoch 98/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.1743 - accuracy: 0.9368\n",
      "Epoch 99/105\n",
      "23565/23565 [==============================] - ETA: 0s - loss: 0.1770 - accuracy: 0.9360 ETA: 0s - l - 1s 36us/step - loss: 0.1770 - accuracy: 0.9357\n",
      "Epoch 100/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.1781 - accuracy: 0.9369 0s - l\n",
      "Epoch 101/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.1791 - accuracy: 0.9370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.1774 - accuracy: 0.9356\n",
      "Epoch 103/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.1706 - accuracy: 0.9409\n",
      "Epoch 104/105\n",
      "23565/23565 [==============================] - 1s 36us/step - loss: 0.1722 - accuracy: 0.9388 0s -\n",
      "Epoch 105/105\n",
      "23565/23565 [==============================] - 1s 37us/step - loss: 0.1780 - accuracy: 0.9343\n",
      "11782/11782 [==============================] - 0s 31us/step\n",
      "Epoch 1/105\n",
      "35347/35347 [==============================] - 2s 43us/step - loss: 0.4158 - accuracy: 0.8349\n",
      "Epoch 2/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.3516 - accuracy: 0.8615 0s - loss: 0.3546 \n",
      "Epoch 3/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.3384 - accuracy: 0.8660\n",
      "Epoch 4/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.3269 - accuracy: 0.8732 0s - loss: 0.3\n",
      "Epoch 5/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.3203 - accuracy: 0.8737\n",
      "Epoch 6/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.3140 - accuracy: 0.8753 0s - loss: 0.3152 - \n",
      "Epoch 7/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.3079 - accuracy: 0.8793\n",
      "Epoch 8/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.3049 - accuracy: 0.8777\n",
      "Epoch 9/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2986 - accuracy: 0.8812\n",
      "Epoch 10/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2980 - accuracy: 0.8831 0s - loss: 0.2976 - accuracy: 0.88\n",
      "Epoch 11/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2947 - accuracy: 0.8840 0s - loss: 0.2963 \n",
      "Epoch 12/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2924 - accuracy: 0.8834\n",
      "Epoch 13/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2896 - accuracy: 0.8848- ETA: 0s - loss: 0.2891 - accu\n",
      "Epoch 14/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2835 - accuracy: 0.8891- ETA: 0s - loss: 0.2847 - accuracy\n",
      "Epoch 15/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2818 - accuracy: 0.8905 0s - loss: 0.2822 - accuracy: 0.89\n",
      "Epoch 16/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2785 - accuracy: 0.8927 0s - loss: 0.2734 - accuracy - ETA: 0s - loss:\n",
      "Epoch 17/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2786 - accuracy: 0.8922 1s - loss: - ETA: 0s - loss: 0.2\n",
      "Epoch 18/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2721 - accuracy: 0.8946 0s - loss: 0.2705  - ETA: 0s - loss: 0.2739 - accura\n",
      "Epoch 19/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2696 - accuracy: 0.8953\n",
      "Epoch 20/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2708 - accuracy: 0.8966\n",
      "Epoch 21/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2686 - accuracy: 0.8954 0s - l\n",
      "Epoch 22/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2638 - accuracy: 0.8984\n",
      "Epoch 23/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2643 - accuracy: 0.8971\n",
      "Epoch 24/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2614 - accuracy: 0.8976\n",
      "Epoch 25/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2601 - accuracy: 0.8998\n",
      "Epoch 26/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2598 - accuracy: 0.8991\n",
      "Epoch 27/105\n",
      "35347/35347 [==============================] - ETA: 0s - loss: 0.2615 - accuracy: 0.89 - ETA: 0s - loss: 0.2615 - accuracy: 0.89 - 1s 37us/step - loss: 0.2617 - accuracy: 0.8992\n",
      "Epoch 28/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2550 - accuracy: 0.9021\n",
      "Epoch 29/105\n",
      "35347/35347 [==============================] - ETA: 0s - loss: 0.2557 - accuracy: 0.9014 ETA: 1s - - ETA: 0s - loss: 0.2578 -  - 1s 37us/step - loss: 0.2564 - accuracy: 0.9012\n",
      "Epoch 30/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2534 - accuracy: 0.9030\n",
      "Epoch 31/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2525 - accuracy: 0.9024 0s - loss: 0.2540 \n",
      "Epoch 32/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2522 - accuracy: 0.9029\n",
      "Epoch 33/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2501 - accuracy: 0.9040\n",
      "Epoch 34/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2522 - accuracy: 0.9023 0s - loss: 0.2524 - accuracy\n",
      "Epoch 35/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2488 - accuracy: 0.9054\n",
      "Epoch 36/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2489 - accuracy: 0.9038\n",
      "Epoch 37/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2485 - accuracy: 0.9043 0s - loss: 0.2483 - accuracy - ETA: 0s - loss: 0.2501 -  - ETA: 0s - loss: 0.2498 - ac\n",
      "Epoch 38/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2478 - accuracy: 0.9069\n",
      "Epoch 39/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2467 - accuracy: 0.9067 0s - loss: 0.2412  - ETA: 0s - loss: 0.2451 \n",
      "Epoch 40/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2457 - accuracy: 0.9092 1s - ETA: 0s - loss: 0.2470 - accu\n",
      "Epoch 41/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2407 - accuracy: 0.9113 0s - loss: 0.2402 - \n",
      "Epoch 42/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2427 - accuracy: 0.9108 0s - loss: 0.2447 \n",
      "Epoch 43/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2420 - accuracy: 0.9101\n",
      "Epoch 44/105\n",
      "35347/35347 [==============================] - 1s 38us/step - loss: 0.2413 - accuracy: 0.9125 0s - loss: 0\n",
      "Epoch 45/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2405 - accuracy: 0.9112\n",
      "Epoch 46/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2421 - accuracy: 0.9104\n",
      "Epoch 47/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2392 - accuracy: 0.9126\n",
      "Epoch 48/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2399 - accuracy: 0.9127\n",
      "Epoch 49/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2390 - accuracy: 0.9124\n",
      "Epoch 50/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2364 - accuracy: 0.9126 1s - loss: 0.2392 - accuracy: 0.91 - ETA: 1s - loss: - ETA: 0s - loss: 0.239\n",
      "Epoch 51/105\n",
      "35347/35347 [==============================] - 1s 38us/step - loss: 0.2360 - accuracy: 0.9141\n",
      "Epoch 52/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2370 - accuracy: 0.9146 0s - loss: 0.2387 -  - ETA: 0s - loss: 0.2361 - accuracy: \n",
      "Epoch 53/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2349 - accuracy: 0.9130\n",
      "Epoch 54/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2361 - accuracy: 0.9140\n",
      "Epoch 55/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2335 - accuracy: 0.9139\n",
      "Epoch 56/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2316 - accuracy: 0.9164 1s - loss: - ETA: 0s - loss: 0.2\n",
      "Epoch 57/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2337 - accuracy: 0.9157\n",
      "Epoch 58/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2288 - accuracy: 0.9179\n",
      "Epoch 59/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2326 - accuracy: 0.9165\n",
      "Epoch 60/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2252 - accuracy: 0.9173\n",
      "Epoch 61/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2300 - accuracy: 0.9179\n",
      "Epoch 62/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2314 - accuracy: 0.9163 0s\n",
      "Epoch 63/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2288 - accuracy: 0.9178 1s - ETA: 0s - loss: 0.2278 - accura\n",
      "Epoch 64/105\n",
      "35347/35347 [==============================] - 1s 36us/step - loss: 0.2271 - accuracy: 0.9186\n",
      "Epoch 65/105\n",
      "35347/35347 [==============================] - 1s 38us/step - loss: 0.2276 - accuracy: 0.9184\n",
      "Epoch 66/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2301 - accuracy: 0.9169\n",
      "Epoch 67/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2234 - accuracy: 0.9189\n",
      "Epoch 68/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2257 - accuracy: 0.9191\n",
      "Epoch 69/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2243 - accuracy: 0.9199 0s - loss: 0.2272 - accura\n",
      "Epoch 70/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2242 - accuracy: 0.9183 0s - loss: 0.2\n",
      "Epoch 71/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2236 - accuracy: 0.9194 1s - loss: 0.2274 - accu - ETA: \n",
      "Epoch 72/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2265 - accuracy: 0.9162 0s - loss: 0\n",
      "Epoch 73/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2233 - accuracy: 0.9210 0s - loss: 0.223\n",
      "Epoch 74/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2245 - accuracy: 0.9194 1s - loss: 0.2155 - ac - ETA: 0s -\n",
      "Epoch 75/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2263 - accuracy: 0.9190\n",
      "Epoch 76/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2258 - accuracy: 0.9187\n",
      "Epoch 77/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2225 - accuracy: 0.9195 0s - loss: 0.2170 - accuracy - ETA: 0s - loss: 0.2172 - accuracy - ETA: 0s - loss: 0.2197 - accura\n",
      "Epoch 78/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2255 - accuracy: 0.9183\n",
      "Epoch 79/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2250 - accuracy: 0.9191\n",
      "Epoch 80/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2226 - accuracy: 0.9193 0s - loss: 0\n",
      "Epoch 81/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2237 - accuracy: 0.9184\n",
      "Epoch 82/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2196 - accuracy: 0.9217 0s - loss: 0.2201 - accura\n",
      "Epoch 83/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2210 - accuracy: 0.9208\n",
      "Epoch 84/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2222 - accuracy: 0.9199\n",
      "Epoch 85/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2227 - accuracy: 0.9203 1s - loss: 0.2236 - accuracy:  -\n",
      "Epoch 86/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2186 - accuracy: 0.9197\n",
      "Epoch 87/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2190 - accuracy: 0.9195\n",
      "Epoch 88/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2242 - accuracy: 0.9185\n",
      "Epoch 89/105\n",
      "35347/35347 [==============================] - 1s 38us/step - loss: 0.2208 - accuracy: 0.9197 0s - l\n",
      "Epoch 90/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2203 - accuracy: 0.9214 0s - loss:\n",
      "Epoch 91/105\n",
      "35347/35347 [==============================] - 1s 38us/step - loss: 0.2210 - accuracy: 0.9190\n",
      "Epoch 92/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2184 - accuracy: 0.9210\n",
      "Epoch 93/105\n",
      "35347/35347 [==============================] - 1s 38us/step - loss: 0.2182 - accuracy: 0.9217\n",
      "Epoch 94/105\n",
      "35347/35347 [==============================] - 1s 38us/step - loss: 0.2183 - accuracy: 0.9214\n",
      "Epoch 95/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2190 - accuracy: 0.9213 1s - - ETA: 0s - loss: 0.2196 - ac\n",
      "Epoch 96/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2161 - accuracy: 0.9220\n",
      "Epoch 97/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2172 - accuracy: 0.9226\n",
      "Epoch 98/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2172 - accuracy: 0.9202\n",
      "Epoch 99/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2190 - accuracy: 0.9214\n",
      "Epoch 100/105\n",
      "35347/35347 [==============================] - ETA: 0s - loss: 0.2183 - accuracy: 0.9222 ETA: 0s - - 1s 37us/step - loss: 0.2185 - accuracy: 0.9221\n",
      "Epoch 101/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2180 - accuracy: 0.9221 0s - loss: 0.2156 - accuracy: 0.92 - ETA: 0s - loss: 0.2160 - accuracy - ETA: 0s - loss: 0.2169 - accura\n",
      "Epoch 102/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2191 - accuracy: 0.9210 0s - los\n",
      "Epoch 103/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2194 - accuracy: 0.9211\n",
      "Epoch 104/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2169 - accuracy: 0.9212\n",
      "Epoch 105/105\n",
      "35347/35347 [==============================] - 1s 37us/step - loss: 0.2148 - accuracy: 0.9222\n",
      "11782/11782 [==============================] - 0s 33us/step\n",
      "Epoch 1/105\n",
      "47129/47129 [==============================] - 2s 43us/step - loss: 0.3987 - accuracy: 0.8356\n",
      "Epoch 2/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.3499 - accuracy: 0.8580\n",
      "Epoch 3/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.3382 - accuracy: 0.8621\n",
      "Epoch 4/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.3299 - accuracy: 0.8637\n",
      "Epoch 5/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.3255 - accuracy: 0.8665 1s - loss: 0.3342 - accuracy - ETA: 1s - ETA: 0s - loss: 0.3263 - accuracy: \n",
      "Epoch 6/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.3222 - accuracy: 0.8671 0s\n",
      "Epoch 7/105\n",
      "47129/47129 [==============================] - 2s 38us/step - loss: 0.3183 - accuracy: 0.8695\n",
      "Epoch 8/105\n",
      "47129/47129 [==============================] - 2s 38us/step - loss: 0.3158 - accuracy: 0.8698 0s - loss: 0.3144 - accuracy: 0.87 - ETA: 0s - loss:\n",
      "Epoch 9/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.3117 - accuracy: 0.8716\n",
      "Epoch 10/105\n",
      "47129/47129 [==============================] - 2s 38us/step - loss: 0.3121 - accuracy: 0.8724\n",
      "Epoch 11/105\n",
      "47129/47129 [==============================] - 2s 38us/step - loss: 0.3050 - accuracy: 0.8740\n",
      "Epoch 12/105\n",
      "47129/47129 [==============================] - 2s 38us/step - loss: 0.3048 - accuracy: 0.8752\n",
      "Epoch 13/105\n",
      "47129/47129 [==============================] - 2s 38us/step - loss: 0.3006 - accuracy: 0.8763 0s - loss:\n",
      "Epoch 14/105\n",
      "47129/47129 [==============================] - 2s 38us/step - loss: 0.2965 - accuracy: 0.8805\n",
      "Epoch 15/105\n",
      "47129/47129 [==============================] - 2s 38us/step - loss: 0.2906 - accuracy: 0.8823 0s\n",
      "Epoch 16/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2893 - accuracy: 0.8836 0s - loss: 0.2889 - accuracy: 0.\n",
      "Epoch 17/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2869 - accuracy: 0.8849\n",
      "Epoch 18/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2842 - accuracy: 0.8848 0s - loss: - ETA: 0s - loss: 0.2840 - accuracy: \n",
      "Epoch 19/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2824 - accuracy: 0.8852\n",
      "Epoch 20/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2786 - accuracy: 0.8872 1s - l - ETA: 0s - loss: 0.2829 - accura - ETA: 0s - loss: 0\n",
      "Epoch 21/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2758 - accuracy: 0.8888\n",
      "Epoch 22/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2749 - accuracy: 0.8894 0s - loss: 0.2745 -  - ETA: 0s - loss: 0.2755 - ac\n",
      "Epoch 23/105\n",
      "47129/47129 [==============================] - 2s 38us/step - loss: 0.2738 - accuracy: 0.8902\n",
      "Epoch 24/105\n",
      "47129/47129 [==============================] - 2s 38us/step - loss: 0.2718 - accuracy: 0.8911\n",
      "Epoch 25/105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2668 - accuracy: 0.8935 0s - loss: - ETA: 0s - loss: 0.2691 - accu\n",
      "Epoch 26/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2635 - accuracy: 0.8969\n",
      "Epoch 27/105\n",
      "47129/47129 [==============================] - ETA: 0s - loss: 0.2673 - accuracy: 0.8937 ETA: 0s - loss: 0.2664 - accuracy: 0. - 2s 37us/step - loss: 0.2667 - accuracy: 0.8941\n",
      "Epoch 28/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2614 - accuracy: 0.8972\n",
      "Epoch 29/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2625 - accuracy: 0.8971 0s - loss: 0.2600 - ac\n",
      "Epoch 30/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2607 - accuracy: 0.8983\n",
      "Epoch 31/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2576 - accuracy: 0.8987\n",
      "Epoch 32/105\n",
      "47129/47129 [==============================] - 2s 38us/step - loss: 0.2570 - accuracy: 0.8999 1s - loss: 0.2427 - accuracy:  - E - ETA: 0s - loss: 0.254\n",
      "Epoch 33/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2573 - accuracy: 0.9010\n",
      "Epoch 34/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2560 - accuracy: 0.9010\n",
      "Epoch 35/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2548 - accuracy: 0.9004\n",
      "Epoch 36/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2541 - accuracy: 0.9011 0s - loss: 0.2555 - accuracy\n",
      "Epoch 37/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2534 - accuracy: 0.9021\n",
      "Epoch 38/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2501 - accuracy: 0.9043 0s - loss: 0.2516 - ac\n",
      "Epoch 39/105\n",
      "47129/47129 [==============================] - ETA: 0s - loss: 0.2526 - accuracy: 0.90 - 2s 37us/step - loss: 0.2522 - accuracy: 0.9020\n",
      "Epoch 40/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2506 - accuracy: 0.9026 0s - loss: 0\n",
      "Epoch 41/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2510 - accuracy: 0.9029 0s -\n",
      "Epoch 42/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2499 - accuracy: 0.9036 1s - loss: 0.2\n",
      "Epoch 43/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2496 - accuracy: 0.9041 0s - loss: 0.2\n",
      "Epoch 44/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2526 - accuracy: 0.9021 0s - loss: 0.2531 - accuracy: 0.90\n",
      "Epoch 45/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2500 - accuracy: 0.9035 1s - loss: 0.2\n",
      "Epoch 46/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2509 - accuracy: 0.9023 1s - loss: 0 - ETA: 0s - loss: 0\n",
      "Epoch 47/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2495 - accuracy: 0.9031\n",
      "Epoch 48/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2488 - accuracy: 0.9035\n",
      "Epoch 49/105\n",
      "47129/47129 [==============================] - 2s 39us/step - loss: 0.2471 - accuracy: 0.9042\n",
      "Epoch 50/105\n",
      "47129/47129 [==============================] - 2s 38us/step - loss: 0.2494 - accuracy: 0.9041\n",
      "Epoch 51/105\n",
      "47129/47129 [==============================] - 2s 38us/step - loss: 0.2486 - accuracy: 0.9039 1s - loss: 0.2473  - ETA: 0s\n",
      "Epoch 52/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2483 - accuracy: 0.9033\n",
      "Epoch 53/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2481 - accuracy: 0.9024\n",
      "Epoch 54/105\n",
      "47129/47129 [==============================] - 2s 38us/step - loss: 0.2461 - accuracy: 0.9053\n",
      "Epoch 55/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2474 - accuracy: 0.9049\n",
      "Epoch 56/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2444 - accuracy: 0.9050\n",
      "Epoch 57/105\n",
      "47129/47129 [==============================] - ETA: 0s - loss: 0.2478 - accuracy: 0.9040 ETA: 0s - 2s 37us/step - loss: 0.2480 - accuracy: 0.9040\n",
      "Epoch 58/105\n",
      "47129/47129 [==============================] - 2s 38us/step - loss: 0.2435 - accuracy: 0.9057 0s - loss: 0.2425 - accura - ETA: 0s - loss: 0.2436 - accuracy: \n",
      "Epoch 59/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2449 - accuracy: 0.9056 0s - loss: 0.2446 - accuracy: 0.90\n",
      "Epoch 60/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2427 - accuracy: 0.9062\n",
      "Epoch 61/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2449 - accuracy: 0.9070 1s - loss: 0\n",
      "Epoch 62/105\n",
      "47129/47129 [==============================] - 2s 38us/step - loss: 0.2429 - accuracy: 0.9077\n",
      "Epoch 63/105\n",
      "47129/47129 [==============================] - 2s 38us/step - loss: 0.2408 - accuracy: 0.9079\n",
      "Epoch 64/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2420 - accuracy: 0.9068\n",
      "Epoch 65/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2442 - accuracy: 0.9059 1s - loss: 0.2398 - accuracy\n",
      "Epoch 66/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2402 - accuracy: 0.9080\n",
      "Epoch 67/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2408 - accuracy: 0.9083 1s - loss: 0.2335 - accuracy: 0.91 - ETA: 1s - loss: 0.2338 - accuracy -\n",
      "Epoch 68/105\n",
      "47129/47129 [==============================] - 2s 38us/step - loss: 0.2424 - accuracy: 0.9065 1s - ETA: 0s - loss: 0 - ETA: 0s - loss: 0.2426 - accuracy: 0.\n",
      "Epoch 69/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2390 - accuracy: 0.9083 0s - loss: 0.2401 - accura\n",
      "Epoch 70/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2371 - accuracy: 0.9090 0s - loss: 0.2367 - accuracy: 0.\n",
      "Epoch 71/105\n",
      "47129/47129 [==============================] - 2s 38us/step - loss: 0.2429 - accuracy: 0.9076 1s - loss: - ETA\n",
      "Epoch 72/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2410 - accuracy: 0.9063 0s - loss: 0.2424 - accuracy - ETA: 0s - loss: 0.2409 - accuracy: \n",
      "Epoch 73/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2397 - accuracy: 0.9085 0s - loss: 0.2387 - accura - ETA: 0s - loss: 0.2412 -  - ETA: 0s - loss: 0.2396 - accuracy: \n",
      "Epoch 74/105\n",
      "47129/47129 [==============================] - ETA: 0s - loss: 0.2402 - accuracy: 0.90 - 2s 37us/step - loss: 0.2402 - accuracy: 0.9084\n",
      "Epoch 75/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2397 - accuracy: 0.9087\n",
      "Epoch 76/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2384 - accuracy: 0.9086\n",
      "Epoch 77/105\n",
      "47129/47129 [==============================] - ETA: 0s - loss: 0.2375 - accuracy: 0.90 - 2s 37us/step - loss: 0.2373 - accuracy: 0.9091\n",
      "Epoch 78/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2395 - accuracy: 0.9093\n",
      "Epoch 79/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2354 - accuracy: 0.9091\n",
      "Epoch 80/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2391 - accuracy: 0.9088 1s - - ETA: 0s -\n",
      "Epoch 81/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2368 - accuracy: 0.9098 1s - loss: 0.2370 - accuracy -\n",
      "Epoch 82/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2385 - accuracy: 0.9088\n",
      "Epoch 83/105\n",
      "47129/47129 [==============================] - ETA: 0s - loss: 0.2375 - accuracy: 0.9105 ETA: 0s - 2s 37us/step - loss: 0.2382 - accuracy: 0.9103\n",
      "Epoch 84/105\n",
      "47129/47129 [==============================] - 2s 38us/step - loss: 0.2396 - accuracy: 0.9100\n",
      "Epoch 85/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2375 - accuracy: 0.9101\n",
      "Epoch 86/105\n",
      "47129/47129 [==============================] - ETA: 0s - loss: 0.2365 - accuracy: 0.91 - 2s 37us/step - loss: 0.2359 - accuracy: 0.9111\n",
      "Epoch 87/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2343 - accuracy: 0.9110 0s - loss: - ETA: 0s - loss: 0.2325 - ac\n",
      "Epoch 88/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2336 - accuracy: 0.9098 1s - loss: - ETA: 0s - loss: 0.2350 -  - ETA: 0s - loss: 0.2336 - accuracy: 0.90\n",
      "Epoch 89/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2351 - accuracy: 0.9108 1s - loss: 0.2 - ETA: 1s - loss: 0 - ETA: 0s - loss: 0.237\n",
      "Epoch 90/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2372 - accuracy: 0.9100 0s - loss: 0.2385 - accu\n",
      "Epoch 91/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2356 - accuracy: 0.9120 \n",
      "Epoch 92/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2344 - accuracy: 0.9107 0s - loss: 0.2357 -  - ETA: 0s - loss: 0.2360 - ac\n",
      "Epoch 93/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2373 - accuracy: 0.9098\n",
      "Epoch 94/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2359 - accuracy: 0.9093 1s - loss: 0.2468 - accuracy: 0.89 - E - ETA: 0s - loss: 0\n",
      "Epoch 95/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2335 - accuracy: 0.9120\n",
      "Epoch 96/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2323 - accuracy: 0.9122\n",
      "Epoch 97/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2349 - accuracy: 0.9109 0s -\n",
      "Epoch 98/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2292 - accuracy: 0.9139 0s - loss: 0.2292 - \n",
      "Epoch 99/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2314 - accuracy: 0.9130 1s - loss: 0.2246 - accuracy - - ETA: 0s - loss: 0.2300 - ac\n",
      "Epoch 100/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2304 - accuracy: 0.9140 0s - loss: 0.2304 - ac\n",
      "Epoch 101/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2325 - accuracy: 0.9124\n",
      "Epoch 102/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2323 - accuracy: 0.9116\n",
      "Epoch 103/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2340 - accuracy: 0.9112\n",
      "Epoch 104/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2315 - accuracy: 0.9119\n",
      "Epoch 105/105\n",
      "47129/47129 [==============================] - 2s 37us/step - loss: 0.2290 - accuracy: 0.9136\n",
      "11782/11782 [==============================] - 0s 34us/step\n",
      "Epoch 1/105\n",
      "58911/58911 [==============================] - 2s 42us/step - loss: 0.4288 - accuracy: 0.8198 0s - loss: 0.4289 - accuracy: 0.81\n",
      "Epoch 2/105\n",
      "58911/58911 [==============================] - ETA: 0s - loss: 0.3796 - accuracy: 0.8397 ETA: 1s - loss: 0 - ETA: 0s - loss: 0.3861  - ETA: 0s - loss: 0.383 - 2s 38us/step - loss: 0.3795 - accuracy: 0.8397\n",
      "Epoch 3/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.3668 - accuracy: 0.8461\n",
      "Epoch 4/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.3621 - accuracy: 0.8473  - ETA: 0s - loss: 0.3634 - accuracy - ETA: 0s - loss: 0.3634 -  - ETA: 0s - loss: 0.3617 - accuracy: 0.84\n",
      "Epoch 5/105\n",
      "58911/58911 [==============================] - 2s 37us/step - loss: 0.3534 - accuracy: 0.8528A: 0s - loss: 0.3523 - accura\n",
      "Epoch 6/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.3523 - accuracy: 0.8528\n",
      "Epoch 7/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.3448 - accuracy: 0.8580 \n",
      "Epoch 8/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.3392 - accuracy: 0.8594 1s - loss: 0.3391 -  -\n",
      "Epoch 9/105\n",
      "58911/58911 [==============================] - ETA: 0s - loss: 0.3336 - accuracy: 0.8635 ETA: 1s - ETA: 0s - loss: 0.3328  - 2s 38us/step - loss: 0.3336 - accuracy: 0.8635\n",
      "Epoch 10/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.3243 - accuracy: 0.8683\n",
      "Epoch 11/105\n",
      "58911/58911 [==============================] - 2s 37us/step - loss: 0.3218 - accuracy: 0.8697\n",
      "Epoch 12/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.3160 - accuracy: 0.8723\n",
      "Epoch 13/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.3112 - accuracy: 0.8749 1s - loss: 0.3128 -  - ETA: 1s - loss: - ETA: 0s - loss:\n",
      "Epoch 14/105\n",
      "58911/58911 [==============================] - 2s 37us/step - loss: 0.3078 - accuracy: 0.8761 0s - loss: 0.3082 - accuracy\n",
      "Epoch 15/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.3042 - accuracy: 0.8787 1s - loss: 0.3051  - ETA: 0s - loss: 0\n",
      "Epoch 16/105\n",
      "58911/58911 [==============================] - ETA: 0s - loss: 0.3021 - accuracy: 0.8791 ETA: 0s - loss: 0.3039 -  - ETA: 0s - loss: 0.3 - 2s 38us/step - loss: 0.3019 - accuracy: 0.8793\n",
      "Epoch 17/105\n",
      "58911/58911 [==============================] - 2s 37us/step - loss: 0.2993 - accuracy: 0.8798\n",
      "Epoch 18/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2970 - accuracy: 0.8808 1s - ETA: 0s - loss: 0.2\n",
      "Epoch 19/105\n",
      "58911/58911 [==============================] - 2s 37us/step - loss: 0.2962 - accuracy: 0.8811 0s - loss: 0.2963 - accuracy\n",
      "Epoch 20/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2937 - accuracy: 0.8822 2s - loss: 0 - ETA: 1s - loss: 0 - ETA: \n",
      "Epoch 21/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2943 - accuracy: 0.8822 0s - loss: 0.2937 - ac\n",
      "Epoch 22/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2918 - accuracy: 0.8831 2s - loss: 0.2908 - accura - ETA: 1s - loss: 0.2931  - ETA: 1s - loss: 0.2938 - ac\n",
      "Epoch 23/105\n",
      "58911/58911 [==============================] - 2s 37us/step - loss: 0.2905 - accuracy: 0.8831 0s - loss: 0.2931 - accura - ETA: 0s - loss: 0.2908 - accuracy: 0.88\n",
      "Epoch 24/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2891 - accuracy: 0.8831 1s - loss: 0.2835 - accuracy - ETA: 1s - loss: 0.2829 - accuracy - - ETA: 0s - loss: 0.2880 - accu\n",
      "Epoch 25/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2849 - accuracy: 0.8860 1s - loss: - ETA: 0s - loss: 0\n",
      "Epoch 26/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2888 - accuracy: 0.8836\n",
      "Epoch 27/105\n",
      "58911/58911 [==============================] - ETA: 0s - loss: 0.2849 - accuracy: 0.88 - 2s 38us/step - loss: 0.2853 - accuracy: 0.8856\n",
      "Epoch 28/105\n",
      "58911/58911 [==============================] - 2s 37us/step - loss: 0.2882 - accuracy: 0.8846\n",
      "Epoch 29/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2871 - accuracy: 0.8834 0s - loss:\n",
      "Epoch 30/105\n",
      "58911/58911 [==============================] - 2s 37us/step - loss: 0.2851 - accuracy: 0.8854\n",
      "Epoch 31/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2814 - accuracy: 0.8878 0s - loss: 0\n",
      "Epoch 32/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2836 - accuracy: 0.8867\n",
      "Epoch 33/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2802 - accuracy: 0.8891\n",
      "Epoch 34/105\n",
      "58911/58911 [==============================] - 2s 37us/step - loss: 0.2813 - accuracy: 0.8868\n",
      "Epoch 35/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2829 - accuracy: 0.8873 0s - loss: 0.2829 - accura\n",
      "Epoch 36/105\n",
      "58911/58911 [==============================] - 2s 37us/step - loss: 0.2798 - accuracy: 0.8895\n",
      "Epoch 37/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2766 - accuracy: 0.8904- ETA: 0s - loss: 0.2764 - accuracy: 0.\n",
      "Epoch 38/105\n",
      "58911/58911 [==============================] - ETA: 0s - loss: 0.2759 - accuracy: 0.88 - 2s 37us/step - loss: 0.2759 - accuracy: 0.8886\n",
      "Epoch 39/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2775 - accuracy: 0.8896\n",
      "Epoch 40/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2772 - accuracy: 0.8892 2s - ETA: 1s - loss: 0.2779 - accura - E\n",
      "Epoch 41/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2753 - accuracy: 0.8902 0s - loss: 0.2741 - accuracy\n",
      "Epoch 42/105\n",
      "58911/58911 [==============================] - 3s 46us/step - loss: 0.2747 - accuracy: 0.8914\n",
      "Epoch 43/105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58911/58911 [==============================] - 2s 41us/step - loss: 0.2760 - accuracy: 0.8904 0s - loss: 0.2776 - accuracy: 0.88 - ETA: 0s - loss: 0.277\n",
      "Epoch 44/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2752 - accuracy: 0.8904 0s - loss: 0.2752 - accuracy: 0.\n",
      "Epoch 45/105\n",
      "58911/58911 [==============================] - 2s 37us/step - loss: 0.2733 - accuracy: 0.8916\n",
      "Epoch 46/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2717 - accuracy: 0.8927\n",
      "Epoch 47/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2739 - accuracy: 0.8918 0s\n",
      "Epoch 48/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2730 - accuracy: 0.8914\n",
      "Epoch 49/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2726 - accuracy: 0.8915\n",
      "Epoch 50/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2730 - accuracy: 0.8918\n",
      "Epoch 51/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2717 - accuracy: 0.8921\n",
      "Epoch 52/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2714 - accuracy: 0.8927\n",
      "Epoch 53/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2732 - accuracy: 0.8911\n",
      "Epoch 54/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2721 - accuracy: 0.8927\n",
      "Epoch 55/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2701 - accuracy: 0.8939 1s - ETA: 0s - los\n",
      "Epoch 56/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2687 - accuracy: 0.8930 1s - loss: 0 - ETA: 0s - loss: - ETA: 0s - loss: 0.2690 - accuracy: 0.\n",
      "Epoch 57/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2675 - accuracy: 0.8950\n",
      "Epoch 58/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2727 - accuracy: 0.8924\n",
      "Epoch 59/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2690 - accuracy: 0.8934\n",
      "Epoch 60/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2699 - accuracy: 0.8944\n",
      "Epoch 61/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2671 - accuracy: 0.8938 1s - ETA: 0s - loss: 0.2672 - accu\n",
      "Epoch 62/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2689 - accuracy: 0.8939 0s - loss: 0 - ETA: 0s - loss: 0.2683 - accuracy: 0.89\n",
      "Epoch 63/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2676 - accuracy: 0.8947\n",
      "Epoch 64/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2649 - accuracy: 0.8956 1s - loss: 0.2639 - accuracy - ETA: 1s - loss: 0.2642 - accuracy\n",
      "Epoch 65/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2668 - accuracy: 0.8929\n",
      "Epoch 66/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2658 - accuracy: 0.8964 0s - loss: 0\n",
      "Epoch 67/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2668 - accuracy: 0.8954\n",
      "Epoch 68/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2642 - accuracy: 0.8958 0s - loss: 0.2636 \n",
      "Epoch 69/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2620 - accuracy: 0.8990 2s - loss: 0.2971 - accuracy: 0.88 - ETA: 2s - loss: 0.2715 - accuracy - ETA: 1s - loss: - ETA: 1s - loss: 0.2623 -  - ETA: \n",
      "Epoch 70/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2660 - accuracy: 0.8975 0s - loss: 0.2660 \n",
      "Epoch 71/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2632 - accuracy: 0.8967\n",
      "Epoch 72/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2639 - accuracy: 0.8977\n",
      "Epoch 73/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2631 - accuracy: 0.8966\n",
      "Epoch 74/105\n",
      "58911/58911 [==============================] - ETA: 0s - loss: 0.2638 - accuracy: 0.8969 ETA: 0s - 2s 38us/step - loss: 0.2638 - accuracy: 0.8969\n",
      "Epoch 75/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2623 - accuracy: 0.8980 0s - loss: 0.2627 - \n",
      "Epoch 76/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2648 - accuracy: 0.8960\n",
      "Epoch 77/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2603 - accuracy: 0.8980 1s - loss: 0.2667 -  - ETA: 1s - loss: 0.2608 - accuracy\n",
      "Epoch 78/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2631 - accuracy: 0.8983\n",
      "Epoch 79/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2613 - accuracy: 0.8995 0s - loss: 0.2612 - accuracy: 0.89\n",
      "Epoch 80/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2606 - accuracy: 0.9003\n",
      "Epoch 81/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2577 - accuracy: 0.9005\n",
      "Epoch 82/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2613 - accuracy: 0.8993\n",
      "Epoch 83/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2596 - accuracy: 0.8992 0s - loss: 0.2605 - accuracy - ETA: 0s - loss: 0.2603 - \n",
      "Epoch 84/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2592 - accuracy: 0.9007\n",
      "Epoch 85/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2584 - accuracy: 0.8990 0s - loss: 0.2589 \n",
      "Epoch 86/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2589 - accuracy: 0.9013\n",
      "Epoch 87/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2608 - accuracy: 0.8986 1s - loss: 0.2\n",
      "Epoch 88/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2616 - accuracy: 0.8993\n",
      "Epoch 89/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2582 - accuracy: 0.9007 0s - loss: 0.2581 - accura\n",
      "Epoch 90/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2593 - accuracy: 0.9003 0s - loss:\n",
      "Epoch 91/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2606 - accuracy: 0.9002 1s - loss: - ETA: 0s - loss: 0.2617 -  - ETA: 0s - loss: 0.2617 \n",
      "Epoch 92/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2613 - accuracy: 0.8994\n",
      "Epoch 93/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2601 - accuracy: 0.9012\n",
      "Epoch 94/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2574 - accuracy: 0.9014 0s - loss: 0.2576 - accu\n",
      "Epoch 95/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2578 - accuracy: 0.9011\n",
      "Epoch 96/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2551 - accuracy: 0.9034 0s - loss: 0\n",
      "Epoch 97/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2578 - accuracy: 0.9004 1s - ETA: 0s - ETA: 0s - loss: 0.2570 - accuracy: 0.\n",
      "Epoch 98/105\n",
      "58911/58911 [==============================] - 2s 37us/step - loss: 0.2585 - accuracy: 0.9008\n",
      "Epoch 99/105\n",
      "58911/58911 [==============================] - 2s 37us/step - loss: 0.2557 - accuracy: 0.9027 0s - los\n",
      "Epoch 100/105\n",
      "58911/58911 [==============================] - 2s 37us/step - loss: 0.2566 - accuracy: 0.9022 2s - los - ETA: 1s - loss: 0.2583 - accu\n",
      "Epoch 101/105\n",
      "58911/58911 [==============================] - 2s 37us/step - loss: 0.2545 - accuracy: 0.9025\n",
      "Epoch 102/105\n",
      "58911/58911 [==============================] - 2s 37us/step - loss: 0.2568 - accuracy: 0.9013 0s - loss: 0.2557 -  - ETA: 0s - loss: 0\n",
      "Epoch 103/105\n",
      "58911/58911 [==============================] - 2s 37us/step - loss: 0.2595 - accuracy: 0.9010\n",
      "Epoch 104/105\n",
      "58911/58911 [==============================] - 2s 38us/step - loss: 0.2560 - accuracy: 0.9035\n",
      "Epoch 105/105\n",
      "58911/58911 [==============================] - 2s 37us/step - loss: 0.2557 - accuracy: 0.9020\n",
      "11782/11782 [==============================] - 0s 34us/step\n"
     ]
    }
   ],
   "source": [
    "mypipeline=CreatePipeLine(ModelByAllTuning,xpoch,xbatch)\n",
    " \n",
    "results = cross_val_score(mypipeline, X, y, cv=xfold)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized:mean= 76.77% std=(5.60%)\n",
      "Standardized:max= 85.54% min=70.60%\n"
     ]
    }
   ],
   "source": [
    "print(\"Standardized:mean= %.2f%% std=(%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "print(\"Standardized:max= %.2f%% min=%.2f%%\" % (results.max()*100, results.min()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize Tune Epcoch and BatchSize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "skfold = StratifiedKFold(n_splits=xsplits, shuffle=True, random_state=xseed)\n",
    "\n",
    "#listEpochs=[50,100,150,300]\n",
    "#listBatchSize=[1,20,32,64,len(X)]\n",
    "listBatchSize=[10,20,32,64]\n",
    "listResults=[]\n",
    "\n",
    "#for n_epochs in listEpochs:\n",
    "for n_bs in listBatchSize:\n",
    "    \n",
    " #print(\"Read DNN=\",n_epochs)   \n",
    " print(\"Batch DNN=\",n_bs)\n",
    "\n",
    " #mypipeline=CreatePipeLine(create_dnn_model1,n_epochs,xbatch)\n",
    " mypipeline=CreatePipeLine(create_dnn_model1,xepoch,n_bs)\n",
    " \n",
    " results = cross_val_score(mypipeline, X, y, cv=skfold)\n",
    " listResults.append(results)\n",
    " print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    \n",
    "    \n",
    "for results in listResults:\n",
    " print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
